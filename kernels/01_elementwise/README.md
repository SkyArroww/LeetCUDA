# Elementwise

## 0x00 说明

包含以下内容：

- [X] elementwise_add_f32_kernel
- [X] elementwise_add_f32x4_kernel(float4向量化版本)
- [X] elementwise_add_f16_kernel(fp16版本)
- [X] elementwise_add_f16x2_kernel(fp16向量化版本)
- [X] elementwise_add_f16x8_kernel(fp16向量化版本)
- [X] elementwise_add_f16x8_pack_kernel(fp16向量化版本, pack)
- [X] PyTorch bindings


## 测试

```bash
# 只测试Ada架构 不指定默认编译所有架构 耗时较长: Volta, Ampere, Ada, Hopper, ...
export TORCH_CUDA_ARCH_LIST=Ada
python3 elementwise.py
```

输出:

```bash
-------------------------------------------------------------------------------------
                                        S=1024, K=1024
           out_f32: [-2.82009077, -0.5666312], time:0.00598025ms
         out_f32x4: [-2.82009077, -0.5666312], time:0.00410318ms
        out_f32_th: [-2.82009077, -0.5666312], time:0.00588393ms
-------------------------------------------------------------------------------------
           out_f16: [-2.8203125, -0.56640625], time:0.00548601ms
         out_f16x2: [-2.8203125, -0.56640625], time:0.00389791ms
         out_f16x8: [-2.8203125, -0.56640625], time:0.00386930ms
     out_f16x8pack: [-2.8203125, -0.56640625], time:0.00386310ms
        out_f16_th: [-2.8203125, -0.56640625], time:0.00583792ms
-------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------
                                        S=1024, K=2048
           out_f32: [4.86788559, -0.03121264], time:0.00742459ms
         out_f32x4: [4.86788559, -0.03121264], time:0.00618076ms
        out_f32_th: [4.86788559, -0.03121264], time:0.00621343ms
-------------------------------------------------------------------------------------
           out_f16: [4.8671875, -0.03118896], time:0.00691319ms
         out_f16x2: [4.8671875, -0.03118896], time:0.00612307ms
         out_f16x8: [4.8671875, -0.03118896], time:0.00572920ms
     out_f16x8pack: [4.8671875, -0.03118896], time:0.00393581ms
        out_f16_th: [4.8671875, -0.03118896], time:0.00588250ms
-------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------
                                        S=1024, K=4096
           out_f32: [-0.76231986, 0.14095858], time:0.01322269ms
         out_f32x4: [-0.76231986, 0.14095858], time:0.01232338ms
        out_f32_th: [-0.76231986, 0.14095858], time:0.01074243ms
-------------------------------------------------------------------------------------
           out_f16: [-0.76269531, 0.14099121], time:0.01203275ms
         out_f16x2: [-0.76269531, 0.14099121], time:0.01031137ms
         out_f16x8: [-0.76269531, 0.14099121], time:0.01143646ms
     out_f16x8pack: [-0.76269531, 0.14099121], time:0.00615382ms
        out_f16_th: [-0.76269531, 0.14099121], time:0.00615549ms
-------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------
                                        S=2048, K=1024
           out_f32: [1.7307409, -1.32978106], time:0.01031971ms
         out_f32x4: [1.7307409, -1.32978106], time:0.00623751ms
        out_f32_th: [1.7307409, -1.32978106], time:0.00620961ms
-------------------------------------------------------------------------------------
           out_f16: [1.73046875, -1.32910156], time:0.00949526ms
         out_f16x2: [1.73046875, -1.32910156], time:0.00459051ms
         out_f16x8: [1.73046875, -1.32910156], time:0.00563455ms
     out_f16x8pack: [1.73046875, -1.32910156], time:0.00408101ms
        out_f16_th: [1.73046875, -1.32910156], time:0.00587082ms
-------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------
                                        S=2048, K=2048
           out_f32: [0.39944169, 0.4179616], time:0.01319146ms
         out_f32x4: [0.39944169, 0.4179616], time:0.01057196ms
        out_f32_th: [0.39944169, 0.4179616], time:0.01073718ms
-------------------------------------------------------------------------------------
           out_f16: [0.3996582, 0.41845703], time:0.01202869ms
         out_f16x2: [0.3996582, 0.41845703], time:0.01047349ms
         out_f16x8: [0.3996582, 0.41845703], time:0.00978184ms
     out_f16x8pack: [0.3996582, 0.41845703], time:0.00608325ms
        out_f16_th: [0.3996582, 0.41845703], time:0.00611973ms
-------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------
                                        S=2048, K=4096
           out_f32: [-0.80888653, 1.04407156], time:0.05168271ms
         out_f32x4: [-0.80888653, 1.04407156], time:0.05156827ms
        out_f32_th: [-0.80888653, 1.04407156], time:0.05278206ms
-------------------------------------------------------------------------------------
           out_f16: [-0.80908203, 1.04394531], time:0.02227950ms
         out_f16x2: [-0.80908203, 1.04394531], time:0.01890278ms
         out_f16x8: [-0.80908203, 1.04394531], time:0.02116466ms
     out_f16x8pack: [-0.80908203, 1.04394531], time:0.01065993ms
        out_f16_th: [-0.80908203, 1.04394531], time:0.01049185ms
-------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------
                                        S=4096, K=1024
           out_f32: [-0.49592674, 0.89274263], time:0.01889443ms
         out_f32x4: [-0.49592674, 0.89274263], time:0.01069832ms
        out_f32_th: [-0.49592674, 0.89274263], time:0.01063895ms
-------------------------------------------------------------------------------------
           out_f16: [-0.49584961, 0.89257812], time:0.01725316ms
         out_f16x2: [-0.49584961, 0.89257812], time:0.00749230ms
         out_f16x8: [-0.49584961, 0.89257812], time:0.00951600ms
     out_f16x8pack: [-0.49584961, 0.89257812], time:0.00611234ms
        out_f16_th: [-0.49584961, 0.89257812], time:0.00612116ms
-------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------
                                        S=4096, K=2048
           out_f32: [-1.08919787, -1.8021946], time:0.03161430ms
         out_f32x4: [-1.08919787, -1.8021946], time:0.02430797ms
        out_f32_th: [-1.08919787, -1.8021946], time:0.02425861ms
-------------------------------------------------------------------------------------
           out_f16: [-1.08886719, -1.80175781], time:0.02227569ms
         out_f16x2: [-1.08886719, -1.80175781], time:0.01926184ms
         out_f16x8: [-1.08886719, -1.80175781], time:0.01773334ms
     out_f16x8pack: [-1.08886719, -1.80175781], time:0.01068354ms
        out_f16_th: [-1.08886719, -1.80175781], time:0.01049089ms
-------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------
                                        S=4096, K=4096
           out_f32: [0.9966324, 2.50321245], time:0.28303432ms
         out_f32x4: [0.9966324, 2.50321245], time:0.28802609ms
        out_f32_th: [0.9966324, 2.50321245], time:0.29519820ms
-------------------------------------------------------------------------------------
           out_f16: [0.99658203, 2.50390625], time:0.07408071ms
         out_f16x2: [0.99658203, 2.50390625], time:0.05362153ms
         out_f16x8: [0.99658203, 2.50390625], time:0.05406880ms
     out_f16x8pack: [0.99658203, 2.50390625], time:0.05133891ms
        out_f16_th: [0.99658203, 2.50390625], time:0.05031800ms
-------------------------------------------------------------------------------------
```

# Elementwise Operations - 逐元素操作优化

本目录展示了CUDA中逐元素加法操作的性能优化技巧，从基础实现到高度优化的版本。

## 任务概览

### 任务1: 基础FP32逐元素加法 (elementwise_add_f32_kernel)
**难度**: ⭐☆☆☆☆  
**目标**: 理解CUDA kernel的基本结构

**实现特点**:
- 每个线程处理一个float元素
- 使用标准C++加法运算符
- 简单的线程索引计算

**优化点**:
- 无特殊优化，作为基准实现
- 适合理解CUDA编程基础概念

**适用场景**: 教学演示、基准测试

---

### 任务2: FP32向量化优化 (elementwise_add_f32x4_kernel)
**难度**: ⭐⭐☆☆☆  
**目标**: 学习内存访问优化技巧

**实现特点**:
- 使用`float4`数据类型进行向量化加载/存储
- 每个线程处理4个float元素
- 通过`FLOAT4`宏进行类型转换

**优化点**:
- **内存带宽优化**: 减少内存事务数量，提高内存带宽利用率
- **向量化**: 利用GPU的向量化能力
- **指令级并行**: 同时处理多个数据元素

**适用场景**: 需要高精度的批量数据处理

---

### 任务3: 基础FP16逐元素加法 (elementwise_add_f16_kernel)
**难度**: ⭐⭐☆☆☆  
**目标**: 学习半精度浮点数操作

**实现特点**:
- 使用`half`数据类型
- 调用CUDA内置函数`__hadd`进行半精度加法
- 内存占用减半

**优化点**:
- **内存效率**: 相比FP32减少50%内存占用
- **计算效率**: 半精度运算通常更快
- **精度权衡**: 在精度和性能之间找到平衡

**适用场景**: 深度学习推理、对精度要求不高的计算

---

### 任务4: FP16向量化优化 (elementwise_add_f16x2_kernel)
**难度**: ⭐⭐⭐☆☆  
**目标**: 结合半精度和向量化优化

**实现特点**:
- 使用`half2`数据类型进行向量化
- 每个线程处理2个half元素
- 结合`__hadd`和向量化优势

**优化点**:
- **双重优化**: 半精度 + 向量化
- **内存带宽**: 进一步提高内存访问效率
- **计算密度**: 增加每个线程的计算量

**适用场景**: 高性能半精度计算

---

### 任务5: FP16批量向量化 (elementwise_add_f16x8_kernel)
**难度**: ⭐⭐⭐⭐☆  
**目标**: 最大化向量化程度

**实现特点**:
- 每个线程处理8个half元素（4个half2向量）
- 使用多个寄存器存储中间结果
- 复杂的边界检查逻辑

**优化点**:
- **线程效率**: 减少线程数量，降低调度开销
- **寄存器利用率**: 充分利用GPU寄存器资源
- **计算吞吐量**: 最大化每个线程的计算量

**适用场景**: 大规模数据处理，追求最高吞吐量

---

### 任务6: FP16打包内存优化 (elementwise_add_f16x8_pack_kernel)
**难度**: ⭐⭐⭐⭐⭐  
**目标**: 掌握高级内存优化技巧

**实现特点**:
- 使用128位内存事务（`LDST128BITS`）
- 本地数组缓存数据
- `#pragma unroll`循环展开优化
- 使用`__hadd2`进行向量化半精度加法

**优化点**:
- **内存事务优化**: 使用128位内存事务最大化带宽
- **循环展开**: 消除循环开销，提高指令级并行
- **向量化指令**: 使用`__hadd2`进行高效的half2运算
- **内存层次优化**: 合理利用寄存器缓存

**适用场景**: 极致性能优化，内存带宽受限的应用

## 性能对比

| Kernel | 精度 | 向量化程度 | 内存优化 | 适用场景 |
|--------|------|------------|----------|----------|
| f32 | FP32 | 1x | 无 | 基准测试 |
| f32x4 | FP32 | 4x | 向量化 | 高精度批量处理 |
| f16 | FP16 | 1x | 无 | 半精度计算 |
| f16x2 | FP16 | 2x | 向量化 | 半精度优化 |
| f16x8 | FP16 | 8x | 批量向量化 | 高吞吐量 |
| f16x8_pack | FP16 | 8x | 128位事务 | 极致性能 |

## 学习路径建议

1. **初学者**: 从`elementwise_add_f32_kernel`开始，理解CUDA基础
2. **进阶**: 学习`elementwise_add_f32x4_kernel`，掌握向量化技巧
3. **半精度**: 研究`elementwise_add_f16_kernel`，了解精度优化
4. **高级优化**: 深入`elementwise_add_f16x8_kernel`，学习批量处理
5. **专家级**: 掌握`elementwise_add_f16x8_pack_kernel`，理解内存优化

## 关键技术点

### 1. 向量化技术
- `float4`/`half2`数据类型的使用
- 向量化加载/存储操作
- 类型转换宏的使用

### 2. 内存优化
- 内存事务大小优化
- 内存访问模式优化
- 寄存器缓存策略

### 3. 计算优化
- 指令级并行
- 循环展开
- 内置函数使用

### 4. 精度优化
- 半精度浮点数运算
- 精度与性能的权衡
- 数值稳定性考虑

## 扩展思考

1. **边界处理**: 如何优化边界检查逻辑？
2. **多精度支持**: 如何扩展到BF16、FP8等精度？
3. **融合操作**: 如何实现更复杂的逐元素操作（如激活函数）？
4. **动态调度**: 如何根据数据大小动态选择最优kernel？
5. **内存布局**: 如何优化不同内存布局下的性能？

这些kernel展示了CUDA编程中逐元素操作的完整优化路径，从基础实现到极致优化，是学习GPU编程的绝佳案例。
